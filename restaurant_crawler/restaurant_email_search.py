#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¤å»³Emailæœå°‹ç¨‹å¼
åŠŸèƒ½ï¼šå¾Excelæª”æ¡ˆä¸­çš„é¤å»³Facebookå°ˆé å’Œå®˜æ–¹ç¶²ç«™æœå°‹Emailåœ°å€
ä½œè€…ï¼šBYOBå¹³å°
ç‰ˆæœ¬ï¼š1.0
"""

import pandas as pd
import requests
import re
import time
import random
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import logging
from urllib.parse import urljoin, urlparse
import os
import argparse

class RestaurantEmailSearcher:
    def __init__(self, max_restaurants=None):
        """åˆå§‹åŒ–Emailæœå°‹å™¨"""
        self.max_restaurants = max_restaurants
        self.setup_logging()
        self.setup_driver()
        
        # Emailæ­£å‰‡è¡¨é”å¼
        self.email_pattern = re.compile(
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
        )
        
        # å¸¸è¦‹çš„ç„¡æ•ˆemail
        self.invalid_emails = {
            'example.com', 'test.com', 'sample.com', 'demo.com',
            'noreply', 'no-reply', 'donotreply', 'admin@example.com'
        }
        
        # è«‹æ±‚é–“éš”è¨­å®š
        self.request_delay = (3, 6)  # 3-6ç§’éš¨æ©Ÿå»¶é²
        
    def setup_logging(self):
        """è¨­å®šæ—¥èªŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('email_search.log', encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
        
    def setup_driver(self):
        """è¨­å®šSelenium WebDriver"""
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # ç„¡é ­æ¨¡å¼
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        
        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            self.wait = WebDriverWait(self.driver, 10)
        except Exception as e:
            self.logger.error(f"ç„¡æ³•å•Ÿå‹•Chrome WebDriver: {e}")
            self.driver = None
            
    def random_delay(self):
        """éš¨æ©Ÿå»¶é²"""
        delay = random.uniform(*self.request_delay)
        time.sleep(delay)
        
    def is_valid_email(self, email):
        """é©—è­‰emailæ˜¯å¦æœ‰æ•ˆ"""
        if not email or len(email) < 5:
            return False
            
        # æª¢æŸ¥æ˜¯å¦ç‚ºç„¡æ•ˆemail
        domain = email.split('@')[1].lower() if '@' in email else ''
        if domain in self.invalid_emails:
            return False
            
        # æª¢æŸ¥emailæ ¼å¼
        return bool(self.email_pattern.match(email))
        
    def extract_emails_from_text(self, text):
        """å¾æ–‡å­—ä¸­æå–email"""
        if not text:
            return []
            
        emails = self.email_pattern.findall(text)
        valid_emails = []
        
        for email in emails:
            email = email.lower().strip()
            if self.is_valid_email(email):
                valid_emails.append(email)
                
        return list(set(valid_emails))  # å»é‡
        
    def search_facebook_email(self, facebook_url):
        """æœå°‹Facebookå°ˆé çš„email"""
        if not self.driver:
            return []
            
        try:
            self.logger.info(f"æ­£åœ¨æœå°‹Facebookå°ˆé : {facebook_url}")
            self.driver.get(facebook_url)
            self.random_delay()
            
            emails = []
            
            # å˜—è©¦å¤šç¨®æ–¹æ³•æœå°‹email
            search_methods = [
                self._search_facebook_about_page,
                self._search_facebook_contact_info,
                self._search_facebook_page_content
            ]
            
            for method in search_methods:
                try:
                    found_emails = method()
                    if found_emails:
                        emails.extend(found_emails)
                        break  # æ‰¾åˆ°emailå°±åœæ­¢
                except Exception as e:
                    self.logger.warning(f"Facebookæœå°‹æ–¹æ³•å¤±æ•—: {e}")
                    continue
                    
            return list(set(emails))  # å»é‡
            
        except Exception as e:
            self.logger.error(f"Facebookå°ˆé æœå°‹å¤±æ•—: {e}")
            return []
            
    def _search_facebook_about_page(self):
        """æœå°‹Facebooké—œæ–¼é é¢"""
        emails = []
        
        # å˜—è©¦é»æ“Šã€Œé—œæ–¼ã€æ¨™ç±¤
        try:
            about_tab = self.wait.until(
                EC.element_to_be_clickable((By.XPATH, "//a[contains(@href, '/about')]"))
            )
            about_tab.click()
            self.random_delay()
            
            # æœå°‹é é¢å…§å®¹
            page_source = self.driver.page_source
            emails = self.extract_emails_from_text(page_source)
            
        except TimeoutException:
            self.logger.info("æœªæ‰¾åˆ°Facebooké—œæ–¼é é¢")
            
        return emails
        
    def _search_facebook_contact_info(self):
        """æœå°‹Facebookè¯çµ¡è³‡è¨Š"""
        emails = []
        
        # æœå°‹è¯çµ¡è³‡è¨Šç›¸é—œå…ƒç´ 
        contact_selectors = [
            "//div[contains(text(), 'è¯çµ¡')]",
            "//div[contains(text(), 'Contact')]",
            "//div[contains(text(), 'Email')]",
            "//div[contains(text(), 'é›»å­éƒµä»¶')]"
        ]
        
        for selector in contact_selectors:
            try:
                elements = self.driver.find_elements(By.XPATH, selector)
                for element in elements:
                    text = element.text
                    found_emails = self.extract_emails_from_text(text)
                    emails.extend(found_emails)
            except Exception:
                continue
                
        return emails
        
    def _search_facebook_page_content(self):
        """æœå°‹Facebooké é¢å…§å®¹"""
        page_source = self.driver.page_source
        return self.extract_emails_from_text(page_source)
        
    def search_website_email(self, website_url):
        """æœå°‹å®˜æ–¹ç¶²ç«™çš„email"""
        emails = []
        
        # è¦æœå°‹çš„é é¢è·¯å¾‘
        search_paths = [
            '',  # é¦–é 
            '/contact',
            '/contact-us',
            '/è¯çµ¡æˆ‘å€‘',
            '/about',
            '/about-us',
            '/é—œæ–¼æˆ‘å€‘'
        ]
        
        for path in search_paths:
            try:
                url = urljoin(website_url, path)
                self.logger.info(f"æ­£åœ¨æœå°‹ç¶²ç«™: {url}")
                
                response = requests.get(url, timeout=10)
                response.raise_for_status()
                
                # æœå°‹é é¢å…§å®¹
                found_emails = self.extract_emails_from_text(response.text)
                if found_emails:
                    emails.extend(found_emails)
                    break  # æ‰¾åˆ°emailå°±åœæ­¢
                    
                self.random_delay()
                
            except Exception as e:
                self.logger.warning(f"ç¶²ç«™æœå°‹å¤±æ•— {url}: {e}")
                continue
                
        return list(set(emails))  # å»é‡
        
    def search_restaurant_email(self, website_url):
        """æœå°‹é¤å»³emailçš„ä¸»è¦æ–¹æ³•"""
        if not website_url or pd.isna(website_url):
            return []
            
        # åˆ¤æ–·æ˜¯Facebookå°ˆé é‚„æ˜¯å®˜æ–¹ç¶²ç«™
        if 'facebook.com' in website_url.lower():
            return self.search_facebook_email(website_url)
        else:
            return self.search_website_email(website_url)
            
    def process_excel_file(self, input_file):
        """è™•ç†Excelæª”æ¡ˆ"""
        try:
            # è®€å–Excelæª”æ¡ˆ
            self.logger.info(f"æ­£åœ¨è®€å–Excelæª”æ¡ˆ: {input_file}")
            df = pd.read_excel(input_file)
            
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_columns = ['name', 'website']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
                
            # æ–°å¢emailæ¬„ä½
            if 'email' not in df.columns:
                df['email'] = ''
            if 'search_status' not in df.columns:
                df['search_status'] = ''
                
            total_restaurants = len(df)
            
            # æ‡‰ç”¨é™åˆ¶å®¶æ•¸
            if self.max_restaurants and self.max_restaurants < total_restaurants:
                df = df.head(self.max_restaurants)
                actual_count = self.max_restaurants
                self.logger.info(f"é™åˆ¶åŸ·è¡Œå®¶æ•¸: {actual_count}/{total_restaurants}")
            else:
                actual_count = total_restaurants
                
            self.logger.info(f"ç¸½å…±éœ€è¦è™•ç† {actual_count} å®¶é¤å»³")
            
            # è™•ç†æ¯å®¶é¤å»³
            for index, row in df.iterrows():
                restaurant_name = row['name']
                website_url = row['website']
                
                self.logger.info(f"æ­£åœ¨è™•ç† ({index+1}/{total_restaurants}): {restaurant_name}")
                
                try:
                    # æœå°‹email
                    emails = self.search_restaurant_email(website_url)
                    
                    if emails:
                        df.at[index, 'email'] = emails[0]  # å–ç¬¬ä¸€å€‹email
                        df.at[index, 'search_status'] = 'found'
                        self.logger.info(f"æ‰¾åˆ°email: {emails[0]}")
                    else:
                        df.at[index, 'email'] = ''
                        df.at[index, 'search_status'] = 'not_found'
                        self.logger.info("æœªæ‰¾åˆ°email")
                        
                except Exception as e:
                    df.at[index, 'email'] = ''
                    df.at[index, 'search_status'] = f'error: {str(e)[:50]}'
                    self.logger.error(f"è™•ç†å¤±æ•—: {e}")
                    
                # éš¨æ©Ÿå»¶é²
                self.random_delay()
                
            # å„²å­˜çµæœ
            if self.max_restaurants and self.max_restaurants < total_restaurants:
                output_file = input_file.replace('.xlsx', f'_with_emails_limit{self.max_restaurants}.xlsx')
            else:
                output_file = input_file.replace('.xlsx', '_with_emails.xlsx')
            df.to_excel(output_file, index=False)
            self.logger.info(f"çµæœå·²å„²å­˜è‡³: {output_file}")
            
            # çµ±è¨ˆçµæœ
            found_count = len(df[df['search_status'] == 'found'])
            self.logger.info(f"æœå°‹å®Œæˆï¼æ‰¾åˆ° {found_count}/{actual_count} å®¶é¤å»³çš„email")
            
            return output_file
            
        except Exception as e:
            self.logger.error(f"è™•ç†Excelæª”æ¡ˆå¤±æ•—: {e}")
            raise
            
    def cleanup(self):
        """æ¸…ç†è³‡æº"""
        if self.driver:
            self.driver.quit()

def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description='é¤å»³Emailæœå°‹ç¨‹å¼')
    parser.add_argument('input_file', help='Excelæª”æ¡ˆè·¯å¾‘')
    parser.add_argument('-n', '--max-restaurants', type=int, 
                       help='é™åˆ¶è™•ç†çš„é¤å»³æ•¸é‡ (ä¾‹å¦‚: -n 10 è¡¨ç¤ºåªè™•ç†å‰10å®¶)')
    
    args = parser.parse_args()
    
    input_file = args.input_file
    max_restaurants = args.max_restaurants
    
    if not os.path.exists(input_file):
        print(f"éŒ¯èª¤: æª”æ¡ˆä¸å­˜åœ¨ - {input_file}")
        return 1
        
    searcher = RestaurantEmailSearcher(max_restaurants=max_restaurants)
    
    try:
        if max_restaurants:
            print(f"é–‹å§‹æœå°‹é¤å»³Email... (é™åˆ¶è™•ç† {max_restaurants} å®¶)")
        else:
            print("é–‹å§‹æœå°‹é¤å»³Email...")
            
        print("é€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ï¼Œè«‹è€å¿ƒç­‰å¾…...")
        
        output_file = searcher.process_excel_file(input_file)
        
        print(f"\nâœ… æœå°‹å®Œæˆï¼")
        print(f"ğŸ“ çµæœæª”æ¡ˆ: {output_file}")
        print(f"ğŸ“Š è©³ç´°æ—¥èªŒ: email_search.log")
        
        return 0
        
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
        return 1
        
    finally:
        searcher.cleanup()

if __name__ == "__main__":
    exit(main())
